{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import photontorch as pt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from deep_learning_utils import DLModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from ring_net import RingNet\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer_flat = torch.nn.Flatten()# output: (batch, 1 * 28 * 28)\n",
    "        self.layer_el = torch.nn.Linear(1 * 28 * 28, 8)# output: (batch, 64)\n",
    "        self.layer_relu = torch.nn.ReLU()\n",
    "        self.layer_ol = RingNet(10, 8, mode=0, wavelength_list=[1.3e-6, 1.35e-6, 1.4e-6, 1.45e-6, 1.5e-6, 1.55e-6, 1.6e-6, 1.65e-6])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        将8个数据用8个波长承载，复用之后输入从同一个光源端口输入\n",
    "        \"\"\"\n",
    "        x = torch.chunk(x, 8, dim = -1)\n",
    "        x = torch.stack(x, dim = 0)\n",
    "        x = torch.squeeze(x, dim = -1)\n",
    "        x = torch.stack([x] * 10, dim = 0).rename('s', 'w', 'b')\n",
    "        x = self.layer_ol(source = x)[-1, :, :, :]\n",
    "        x = torch.sum(x, dim = 0) # 在波长维度求和\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_list = [1.3e-6, 1.35e-6, 1.4e-6, 1.45e-6, 1.5e-6, 1.55e-6, 1.6e-6, 1.65e-6]\n",
    "env = pt.Environment(t_start = 0, t_end = 1e-11, dt = 1e-12, wl = wavelength_list, grad=True, freqdomain=True)\n",
    "pt.set_environment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "model = Model()\n",
    "# 超参数\n",
    "train_batch = 16\n",
    "test_batch = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# 数据集\n",
    "trainset = datasets.MNIST(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "testset = datasets.MNIST(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "subtrainset = torch.utils.data.Subset(trainset, range(160))\n",
    "subtestset = torch.utils.data.Subset(testset, range(10))\n",
    "\n",
    "# 训练测试模块\n",
    "dl = DLModule(model=model, loss_fn=loss_fn, optim=optim, train_set=trainset, \n",
    "              test_set=testset, train_batch=train_batch, test_batch=test_batch)\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "label = torch.tensor([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.train()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "total_train_loss = 0\n",
    "total_train_step = 0\n",
    "for i in range(20):\n",
    "    predict = model(input)\n",
    "    loss = loss_fn(predict, label)\n",
    "    total_train_loss += loss.item()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_train_step += 1\n",
    "    print(f\"Train steps : {total_train_step}\",  f\"Loss : {loss.item()}\")\n",
    "\n",
    "print(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-115.3332, -115.3332, -115.3332, -115.3332, -115.3331,  -83.4024,\n",
      "         -115.3332, -115.3332, -115.3332, -115.3332]], grad_fn=<SubBackward0>)\n",
      "tensor([5])\n"
     ]
    }
   ],
   "source": [
    "out = model(input)\n",
    "print(out)\n",
    "print(out.argmax(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photontorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
