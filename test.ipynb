{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import photontorch as pt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from deep_learning_utils import DLModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wavelength_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1.3e-6\u001b[39m, \u001b[38;5;241m1.35e-6\u001b[39m, \u001b[38;5;241m1.4e-6\u001b[39m, \u001b[38;5;241m1.45e-6\u001b[39m, \u001b[38;5;241m1.5e-6\u001b[39m, \u001b[38;5;241m1.55e-6\u001b[39m, \u001b[38;5;241m1.6e-6\u001b[39m, \u001b[38;5;241m1.65e-6\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241m.\u001b[39mEnvironment(t_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, t_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-11\u001b[39m, dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m, wl \u001b[38;5;241m=\u001b[39m wavelength_list, grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, freqdomain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m pt\u001b[38;5;241m.\u001b[39mset_environment(env)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pt' is not defined"
     ]
    }
   ],
   "source": [
    "wavelength_list = [1.3e-6, 1.35e-6, 1.4e-6, 1.45e-6, 1.5e-6, 1.55e-6, 1.6e-6, 1.65e-6]\n",
    "env = pt.Environment(t_start = 0, t_end = 1e-11, dt = 1e-12, wl = wavelength_list, grad=True, freqdomain=True)\n",
    "pt.set_environment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建网络\n",
    "model = Model()\n",
    "# 超参数\n",
    "train_batch = 16\n",
    "test_batch = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# 数据集\n",
    "trainset = datasets.MNIST(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "testset = datasets.MNIST(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "subtrainset = torch.utils.data.Subset(trainset, range(160))\n",
    "subtestset = torch.utils.data.Subset(testset, range(10))\n",
    "\n",
    "# 训练测试模块\n",
    "dl = DLModule(model=model, loss_fn=loss_fn, optim=optim, train_set=trainset, \n",
    "              test_set=testset, train_batch=train_batch, test_batch=test_batch)\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from ring_net import RingNet\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer_flat = torch.nn.Flatten()# output: (batch, 1 * 28 * 28)\n",
    "        self.layer_el = torch.nn.Linear(1 * 28 * 28, 8)# output: (batch, 64)\n",
    "        self.layer_relu = torch.nn.ReLU()\n",
    "        self.layer_ol = RingNet(10, 8, mode=0, wavelength_list=[1.3e-6, 1.35e-6, 1.4e-6, 1.45e-6, 1.5e-6, 1.55e-6, 1.6e-6, 1.65e-6])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        将8个数据用8个波长承载，复用之后输入从同一个光源端口输入\n",
    "        \"\"\"\n",
    "        x = torch.chunk(x, 8, dim = -1)\n",
    "        x = torch.stack(x, dim = 0)\n",
    "        x = torch.squeeze(x, dim = -1)\n",
    "        x = torch.stack([x] * 10, dim = 0).rename('s', 'w', 'b')\n",
    "        x = self.layer_ol(source = x)[-1, :, :, :]\n",
    "        x = torch.sum(x, dim = 0) # 在波长维度求和\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.ones(1, 8)\n",
    "label = torch.tensor([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.train()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train steps : 1 Loss : 3.799912185593856e+16\n",
      "Train steps : 2 Loss : nan\n",
      "Train steps : 3 Loss : nan\n",
      "Train steps : 4 Loss : nan\n",
      "Train steps : 5 Loss : nan\n",
      "Train steps : 6 Loss : nan\n",
      "Train steps : 7 Loss : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m total_train_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(predict, label)\n\u001b[1;32m      6\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(x, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([x] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_ol\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :, :]\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(x, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 在波长维度求和\u001b[39;00m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/photontorch/networks/network.py:756\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, source, power, detector)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# reinitialize the network if the current environment does not correspond\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# to the previous environment\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m current_environment() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled():\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_source(source)\n\u001b[1;32m    760\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/photontorch/networks/network.py:528\u001b[0m, in \u001b[0;36mNetwork.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m rx, ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ml, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# 3. Calculate Smlml@inv(P)@Cmlmc\u001b[39;00m\n\u001b[1;32m    526\u001b[0m rx, ix \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    527\u001b[0m     (rSmlml)\u001b[38;5;241m.\u001b[39mbmm(rx) \u001b[38;5;241m-\u001b[39m (iSmlml)\u001b[38;5;241m.\u001b[39mbmm(ix),\n\u001b[0;32m--> 528\u001b[0m     \u001b[43m(\u001b[49m\u001b[43miSmlml\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (rSmlml)\u001b[38;5;241m.\u001b[39mbmm(ix),\n\u001b[1;32m    529\u001b[0m )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# 4. Calculate Cmcml@Smlml@inv(P)@Cmlmc\u001b[39;00m\n\u001b[1;32m    532\u001b[0m rCmcml \u001b[38;5;241m=\u001b[39m rCmcml[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mexpand(env\u001b[38;5;241m.\u001b[39mnum_wl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ml)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/_tensor.py:1023\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1023\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert(ret, \u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_train_loss = 0\n",
    "total_train_step = 0\n",
    "for i in range(20):\n",
    "    predict = model(input)\n",
    "    loss = loss_fn(predict, label)\n",
    "    total_train_loss += loss.item()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_train_step += 1\n",
    "    print(f\"Train steps : {total_train_step}\",  f\"Loss : {loss.item()}\")\n",
    "\n",
    "print(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-115.3332, -115.3332, -115.3332, -115.3332, -115.3331,  -83.4024,\n",
      "         -115.3332, -115.3332, -115.3332, -115.3332]], grad_fn=<SubBackward0>)\n",
      "tensor([5])\n"
     ]
    }
   ],
   "source": [
    "out = model(input)\n",
    "print(out)\n",
    "print(out.argmax(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photontorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
