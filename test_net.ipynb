{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import photontorch as pt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from deep_learning_utils import DLModule\n",
    "from ring_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/opt/homebrew/anaconda3/envs/photontorch/lib/python3.9/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test loss: 5064.642727\n",
      "Test accuracy : 0.8624\n",
      "准确率为 0.8624\n"
     ]
    }
   ],
   "source": [
    "wavelength_list =[1.53e-6, 1.54e-6, 1.55e-6, 1.56e-6] \n",
    "env = pt.Environment(t_start = 0, t_end = 1e-11, dt = 5e-12, wl = wavelength_list, grad=True, freqdomain=True)\n",
    "pt.set_environment(env)\n",
    "\n",
    "# 搭建网络\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"best_model_para.pth\"), strict=False)\n",
    "# 超参数\n",
    "train_batch = 3000\n",
    "test_batch = 2000\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# 数据集\n",
    "trainset = datasets.MNIST(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "testset = datasets.MNIST(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "# subtrainset = torch.utils.data.Subset(trainset, range(100))\n",
    "# subtestset = torch.utils.data.Subset(testset, range(10))\n",
    "\n",
    "# 训练测试模块\n",
    "dl = DLModule(model=model, loss_fn=loss_fn, optim=optim, train_set=trainset, \n",
    "              test_set=testset, train_batch=train_batch, test_batch=test_batch)\n",
    "dl.test_mode()\n",
    "print(\"准确率为\", dl.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer_el.weight', Parameter containing:\n",
      "tensor([[-0.0005, -0.0149, -0.0319,  ...,  0.0207,  0.0294, -0.0273],\n",
      "        [ 0.0052, -0.0357,  0.0323,  ..., -0.0213,  0.0235,  0.0012],\n",
      "        [-0.0303,  0.0167, -0.0019,  ..., -0.0089,  0.0216,  0.0243],\n",
      "        [ 0.0294,  0.0141,  0.0013,  ...,  0.0173, -0.0092,  0.0059]],\n",
      "       requires_grad=True))\n",
      "('layer_el.bias', Parameter containing:\n",
      "tensor([0.0308, 0.1587, 0.4523, 0.3791], requires_grad=True))\n",
      "('layer_ol.ring_array.ring0_0.wg2.phase', Parameter containing:\n",
      "tensor(-0.0820, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring1_0.wg2.phase', Parameter containing:\n",
      "tensor(0.0126, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring2_0.wg2.phase', Parameter containing:\n",
      "tensor(-0.0532, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring3_0.wg2.phase', Parameter containing:\n",
      "tensor(0.0367, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring4_0.wg2.phase', Parameter containing:\n",
      "tensor(4.7317e-08, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring5_0.wg2.phase', Parameter containing:\n",
      "tensor(-0.0447, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring6_0.wg2.phase', Parameter containing:\n",
      "tensor(-0.0556, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring7_0.wg2.phase', Parameter containing:\n",
      "tensor(3.7806e-05, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring8_0.wg2.phase', Parameter containing:\n",
      "tensor(0.0355, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring9_0.wg2.phase', Parameter containing:\n",
      "tensor(-0.0146, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring0_1.wg2.phase', Parameter containing:\n",
      "tensor(2.9601e-07, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring1_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0890, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring2_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0476, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring3_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0418, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring4_1.wg2.phase', Parameter containing:\n",
      "tensor(-0.0003, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring5_1.wg2.phase', Parameter containing:\n",
      "tensor(-0.0159, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring6_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0004, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring7_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0610, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring8_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0319, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring9_1.wg2.phase', Parameter containing:\n",
      "tensor(0.0298, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring0_2.wg2.phase', Parameter containing:\n",
      "tensor(0.0601, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring1_2.wg2.phase', Parameter containing:\n",
      "tensor(0.0056, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring2_2.wg2.phase', Parameter containing:\n",
      "tensor(0.0083, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring3_2.wg2.phase', Parameter containing:\n",
      "tensor(-0.0482, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring4_2.wg2.phase', Parameter containing:\n",
      "tensor(-0.0452, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring5_2.wg2.phase', Parameter containing:\n",
      "tensor(-0.0598, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring6_2.wg2.phase', Parameter containing:\n",
      "tensor(1.5314e-06, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring7_2.wg2.phase', Parameter containing:\n",
      "tensor(-0.1758, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring8_2.wg2.phase', Parameter containing:\n",
      "tensor(0.0329, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring9_2.wg2.phase', Parameter containing:\n",
      "tensor(-0.0747, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring0_3.wg2.phase', Parameter containing:\n",
      "tensor(-1.9016e-07, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring1_3.wg2.phase', Parameter containing:\n",
      "tensor(0.0406, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring2_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.0225, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring3_3.wg2.phase', Parameter containing:\n",
      "tensor(0.0120, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring4_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.1142, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring5_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.0227, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring6_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.0679, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring7_3.wg2.phase', Parameter containing:\n",
      "tensor(0.0048, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring8_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.0312, dtype=torch.float64, requires_grad=True))\n",
      "('layer_ol.ring_array.ring9_3.wg2.phase', Parameter containing:\n",
      "tensor(-0.0304, dtype=torch.float64, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photontorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
